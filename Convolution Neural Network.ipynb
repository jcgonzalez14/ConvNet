{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANt5Z6ALSKzo"
   },
   "source": [
    "# CNN Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhtKpOyKSKzt"
   },
   "source": [
    "## 1. Introduction\n",
    "Hello! My selfgiven name is the Stats Whisper and I'm back with another Data Science topic that is one of the hottest things in research now: Deep Learning. Even if you lend a very small ear to what is going on in the scientific community, you have probably heard of Deep Learning. It is the backbone of some of the coolest things today like: self-driving cars, facial-recongition, virtual digital assistants and [accurately estimating how a human on the other side of a wall is standing/sitting/walking just from perturbations in Wifi signals caused by that human](http://rfpose.csail.mit.edu/) (don't know what good that is for but hey).\n",
    "\n",
    "\n",
    "Believe or not, neural networks have been around for a while but the slashed costs of computing power paired with the increased computing capacity are the impetus behind the eponential growth of the field. \n",
    "\n",
    "With the expantion of the field, grew different kinds of neural networks for different purposes. \n",
    "Today, we will be focusing on a particular type of neural network called a convolution neural network (CNN for short). Research has found these models to be excellent when it comes to image recognition. And image recognition we shall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uNQU3cEbtW0"
   },
   "source": [
    "## 2. Convolution Neural Network\n",
    "\n",
    "Okay, so before we dive into what exactly a convolution neural network is let us strip it down to its essence, just a plain and simple vanilla neural network. Like the depths of the universe, you can go as far, wide and deep into this topic and you'll probably never get to the bottom of it because of the presence of a very active area of research that is pushing the field even further. \n",
    "\n",
    "So what exactly is a neural network? Well, it's actually pretty simple: a function. A function that can be very complex but a function nevertheless. \n",
    "\n",
    "At its most basic core, a neural network has 3 parts:\n",
    " - input layer\n",
    " - hidden layer\n",
    " - output layer\n",
    "\n",
    "As the name suggests, the input layer is where the data is feed into the network. The mysterious hidden layer is where all the action is happening and output layer is the result you wish to acquire. \n",
    "\n",
    "In relation to a function, take the ubiquitous function of simple line found in every Algebra class: y = mx+b. The x in this case is the input layer. The m and b are hidden layer and the y is the output layer. \n",
    "\n",
    "Easy right?\n",
    "\n",
    "A convolution neural network does the exact same thing by using an image as input, crunches some numbers then does a prediction as an output.\n",
    "\n",
    "There is a great amount of content out there that goes into good detail and further explains how the mechanics of a convolution neural network work. It can get very mathematical and technical really quick so you can easily lose an audience. But if you are really interested to go further, I found [this video](https://www.youtube.com/watch?v=aircAruvnKk) to be a lifesaver for my Big Data class while I was learning neural networks in grad school.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYK8DjBBSKzv"
   },
   "source": [
    "## 3. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KvhLsW6SKzw"
   },
   "source": [
    "If you ever wondered how in the world your new Iphone has the capacity to determine whether or not it's your face or someone else's face with amazing accuracy to unlock your phone using Face ID, well you have just witnessed the power of neural networks first hand. Apple trained the neural networks using billions of images then took the result and installed it into your iphone. Pretty cool, huh?\n",
    "\n",
    "Since neural networks are great at determining who's face that image belongs to, what if we could weild this technology to find my celebrity doppleganger. \n",
    "\n",
    "In my much younger (and more atheltic days), some of friends would say I looked like soccer superstar Neymar while others would disagree. Well, let's use a neural network to settle the debate for us. Let's feed it a bunch of pictures from world class athletes and have the CNN decide who I resemble to most. \n",
    "\n",
    "To make this worthwhile, let's use 7 different athletes and see what the model returns. If I indeed look like Neymar then when I feed it an image of myself then it will output a prediction of Neymar. Sounds like a plan, right? All right, let's roll. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "al-5EirTF1-K"
   },
   "source": [
    "### 3.1 Loading the Data\n",
    "\n",
    "Okay so first let's load the data. We'll be using Google's Colab product to leverage the powerfull GPU available, slashing runtimes instead waiting forever for it to run locally on my MacBook.\n",
    "\n",
    "This data was acquired from Google Images after being cropped and reshaped. The data includes 30 images for Neymar, Leonel Messi, Cristiano Ronaldo, Kevin Durant, Odel Beckham, Steph Curry, Arron Rodgers.\n",
    "\n",
    "The data was split 80/20 for training and validation purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iL5s_wKZF1-L"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/content/gdrive/My Drive/CNN/data/train',  # this is the target directory\n",
    "        target_size=(197, 197),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/content/gdrive/My Drive/CNN/data/validation',\n",
    "        target_size=(197, 197),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "label_map = validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT6CDsJ_F1-R"
   },
   "source": [
    "### 3.2 Transfer Learning\n",
    "\n",
    "Instead of creating a CNN from scratch and having to use valuable time and resources training/testing different models, what we can do instead is use a model that has already been trained then slightly customize it to fit our objectives. The formal term for this technique is called \"transfer learning\". \n",
    "\n",
    "Transfer learning is great because you can take neural networks and their respective weights painstakingly developed by the pros then reuse those models for other purposes. \n",
    "\n",
    "While TensorFlow is the gold standard for neural networks I perfer to use Keras because of the way it simplyfies long cumbersome TensorFlow code into a few simple lines of code and, more importantly, Keras comes pre-trained models available for execute transfer learning. \n",
    "\n",
    "Today, we'll be using a CNN developed by researchers at Cornell University called [MobileNetV2](https://arxiv.org/abs/1801.04381). While most of the available models have compariable accuracy rates, this model is \"lightweight\" with it's fewer total parameters in the model and thus faster to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Byi6i67RF1-W"
   },
   "outputs": [],
   "source": [
    "#importing the relevant libraries and modules for CNN\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras\n",
    "\n",
    "input_tensor = Input(shape=(197, 197, 3))\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = MobileNetV2(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# since we have 7 classes, we need a final layer that predicts 7 classes. \n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "custom_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# compile the model\n",
    "custom_model.compile(optimizer=keras.optimizers.Adam(lr=0.00009), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"/content/gdrive/My Drive/CNN/tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
    "\n",
    "custom_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,\n",
    "        callbacks = [tensorboard],\n",
    "        epochs=15,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        verbose=1)\n",
    "\n",
    "custom_model.save(\"/content/gdrive/My Drive/CNN/custom_model_weights.h5\")\n",
    "\n",
    "with open('/content/gdrive/My Drive/CNN/custom_model_architecture.json', 'w') as f:\n",
    "    f.write(custom_model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfjBWVw-F1-c"
   },
   "source": [
    "You'll notice that the accuracy of the model rapidly increases after each iteration. That's because the model is leveraging the features it previously learned and putting them to use to make sense of the images it is being feed. You are witnessing the power of transfer learning in action.\n",
    "\n",
    "So now with a fully trained model at hand, we can use machine learning to help us with in our quest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EMAC36xKT_F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading Model\n",
      "Loaded associated weights for model\n",
      "Found 42 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#need to hide this cell \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "batch_size = 64\n",
    "\n",
    "#Loading model and associated weights already compiled. \n",
    "# Model reconstruction from JSON file\n",
    "with open('custom_model_architecture.json', 'r') as f:\n",
    "    custom_model = model_from_json(f.read())\n",
    "    print(\"Finished Loading Model\")\n",
    "    \n",
    "# Load weights into the new model\n",
    "custom_model.load_weights('custom_model_weights.h5')\n",
    "print(\"Loaded associated weights for model\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(197, 197),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "label_map = validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wn0pryWjMPjT"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOkQ3THhMOBo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_output(prediction,label_map):    \n",
    "    results = {list(label_map.keys())[i]:prediction[0][i] for i in range(len(prediction[0]))}\n",
    "    for key in sorted(results, key=lambda k: results[k],reverse=True):\n",
    "        print('%12s'%key,round(results[key]*100,2),\"%\")\n",
    "    print()\n",
    "\n",
    "def predict_image(image_path,model,label_map):\n",
    "    #img_path = 'data/julio.jpg'\n",
    "    img = image.load_img(image_path, target_size=(197, 197))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x.reshape(1,197,197,3)\n",
    "    x = preprocess_input(x)\n",
    "    probabilities = model.predict(x)\n",
    "    model_output(probabilities,label_map)\n",
    "\n",
    "\n",
    "predict_image(\"data/julio.jpg\",custom_model,label_map)\n",
    "predict_image(\"data/julio1.jpg\",custom_model,label_map)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convolution Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
