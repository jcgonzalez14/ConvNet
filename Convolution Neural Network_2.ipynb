{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolution Neural Network.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "ANt5Z6ALSKzo"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Facial Recognition"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FhtKpOyKSKzt"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "Hey guys, the Stats Whisper is back with another task at hand. This time we will be using a convulution neural network to resolve a doopleganger debate. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JYK8DjBBSKzv"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Explianed"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7KvhLsW6SKzw"
      },
      "cell_type": "markdown",
      "source": [
        "- images\n",
        "- videos \n",
        "- mathematically explained\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZRucqAgBSKzx"
      },
      "cell_type": "markdown",
      "source": [
        "# Application"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Tmu0Q1k_SKzz"
      },
      "cell_type": "markdown",
      "source": [
        "Importing appropriate libraries and image data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6iIKYLobSKz0",
        "outputId": "8206a6f1-87f8-4f4b-9153-1f745de882e2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "#VGG16 is not VGGFACE. VGG16 includes all types of images and not just faces. \n",
        "\n",
        "#keras.applications.imagenet_utils import _obtain_input_shape\n",
        "model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xPMuQORuSKz_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "K.set_image_dim_ordering('th')\n",
        "from time import time\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cWaNWMgtSK0E",
        "outputId": "1eff896c-37d9-4e32-f012-edb2214f8d74",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5 \n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',  # this is the target directory\n",
        "        target_size=(250, 250),  # all images will be resized to 250x250\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'data/test',\n",
        "        target_size=(250, 250),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70 images belonging to 2 classes.\n",
            "Found 70 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TGKYFda6SK0L",
        "outputId": "a4b92095-0673-49d7-e9dd-962129b93932",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=20,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=10,\n",
        "        callbacks = [tensorboard])\n",
        "model.save_weights('first_try.h5')  # always save your weights after training or during training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 11.4438 - acc: 0.2900 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 13s 637ms/step - loss: 11.2827 - acc: 0.3000 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 11.2827 - acc: 0.3000 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 13s 639ms/step - loss: 11.4438 - acc: 0.2900 - val_loss: 11.6050 - val_acc: 0.2800\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 10.9603 - acc: 0.3200 - val_loss: 10.6379 - val_acc: 0.3400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ral9E7SFSK0S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4HQYJlJdSK0X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}