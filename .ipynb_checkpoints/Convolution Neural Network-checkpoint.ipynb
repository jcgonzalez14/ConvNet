{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANt5Z6ALSKzo"
   },
   "source": [
    "# CNN Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhtKpOyKSKzt"
   },
   "source": [
    "# 1. Introduction\n",
    "Hello! My selfgiven name is the Stats Whisper and I'm back with another Data Science topic that is one of the hottest things in research now: Deep Learning. Even if you lend a very small ear to what is going on in the scientific community, you have probably heard of Deep Learning. It is the backbone of some of the coolest things in the modern era like: self-driving cars, facial-recongition, virtual digital assistants and [accurately estimating how a human on the other side of a wall is standing/sitting/walking just from perturbations in Wifi signals caused by that human](http://rfpose.csail.mit.edu/) (don't know what good that is but hey).\n",
    "\n",
    "\n",
    "Believe or not, neural networks have been around for a while but the slashed costs of computing power paired with the increased computing capacity are the impetus behind the eponential growth of the field. \n",
    "\n",
    "This time we will be using a convulution neural network (CNN for short) to resolve a doopleganger debate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so before we dive into what exactly a convulution neural network is let us strip it down to its essence, just a plain and simple vanilla neural network. Like the depths of the universe, you can go as far, wide and deep into this topic and you'll probably never get to the bottom of it because of the presence of a very active area of research that is pushing the field even further. \n",
    "\n",
    "So what exactly is a neural network? Well, it's actually pretty simple: a function. A function that can be very complex but a function nevertheless. \n",
    "\n",
    "At its most basic core, a neural network has 3 parts:\n",
    " - input layer\n",
    " - hidden layer\n",
    " - output layer\n",
    "\n",
    "As the name suggests, the input layer is where the data is feed into the network. The mysterious hidden layer is where all the action is happening and output layer is the result you wish to acquire. \n",
    "\n",
    "In relation to a function, take the ubiquitous function of simple line found in every Algebra class: y = mx+b. The x in this case is the input layer. The m and b are hidden layer and the y is the output layer. \n",
    "\n",
    "Easy right?\n",
    "\n",
    "A convolution neural network does the exact same thing by using an image as input, crunches some numbers then does a prediction as an output.\n",
    "\n",
    "There is a great amount of content out there that goes into good detail and further explains how the mechanics of a convolution neural network work. While I was learning neural networks in grad school, I found [this video](https://www.youtube.com/watch?v=aircAruvnKk) to be a lifesaver for my Big Data class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYK8DjBBSKzv"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KvhLsW6SKzw"
   },
   "source": [
    "Before moving forward, let's take a second to see ask why the name Convolution Neural Neural. In mathematics, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRucqAgBSKzx"
   },
   "source": [
    "# 2. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tmu0Q1k_SKzz"
   },
   "source": [
    "## 2.1 Creating Basic CNN using Local Data with 3 classes\n",
    "    -Neymar\n",
    "    -Rafinha\n",
    "    -Cristiano Ronaldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPMuQORuSKz_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 250, 250)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWaNWMgtSK0E",
    "outputId": "1eff896c-37d9-4e32-f012-edb2214f8d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5 \n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(250, 250),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(250, 250),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGKYFda6SK0L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliogonzalez/Library/Python/3.6/lib/python/site-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 44s 2s/step - loss: nan - acc: 0.3000 - val_loss: nan - val_acc: 0.3400\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 43s 2s/step - loss: nan - acc: 0.3400 - val_loss: nan - val_acc: 0.3600\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 42s 2s/step - loss: nan - acc: 0.3400 - val_loss: nan - val_acc: 0.3000\n",
      "Epoch 4/5\n",
      "12/20 [=================>............] - ETA: 14s - loss: nan - acc: 0.3333"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        callbacks = [tensorboard])\n",
    "model.save_weights('basic3_cnn.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnMG5fU_PZ5w"
   },
   "source": [
    "# 3. Advanced Aplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oymEff8Qv7m"
   },
   "source": [
    "## 3.1 ResNet50 w/same local data\n",
    "-Emphasize significance of pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HQYJlJdSK0X",
    "outputId": "443e2455-6fb7-472a-841d-48193006b03a"
   },
   "outputs": [],
   "source": [
    "#see if you can run it locally first, if not then will need to use Google's colab\n",
    "\n",
    "from keras.engine import  Model\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten,Input,Dropout,Activation,Conv2D\n",
    "import keras\n",
    "\n",
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "resnet50_model = VGGFace(model='resnet50',include_top=False, input_shape=(224, 224, 3))\n",
    "last_layer = resnet50_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "out = Dense(nb_class, activation='softmax', name='classifier')(x)\n",
    "custom_resnet50_model = Model(resnet50_model.input, out)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "custom_resnet50_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "         optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoAbZ1__PZ55",
    "outputId": "e2d98c78-70b8-4f0a-a88e-bc30bb27837b"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "batch_size = 5 \n",
    "\n",
    "train_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
    "\n",
    "custom_resnet50_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djds5D0oRCu1"
   },
   "source": [
    "## 3.2 ResNet50 on LFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COcelS9sPZ5_"
   },
   "outputs": [],
   "source": [
    "#Since we are going to use Google's colab we need to run the following code\n",
    "#see if you can hide it if possible\n",
    "!pip install keras_vggface\n",
    "!pip install Keras==2.2\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten,Input,Dropout,Activation,Conv2D\n",
    "import keras\n",
    "\n",
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "resnet50_model = VGGFace(model='resnet50',include_top=False, input_shape=(224, 224, 3))\n",
    "last_layer = resnet50_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "out = Dense(nb_class, activation='softmax', name='classifier')(x)\n",
    "custom_resnet50_model = Model(resnet50_model.input, out)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "custom_resnet50_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "         optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "batch_size = 5 \n",
    "\n",
    "train_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(data_format=\"channels_last\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/content/gdrive/My Drive/data/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/content/gdrive/My Drive/data/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
    "\n",
    "custom_resnet50_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convolution Neural Network.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
