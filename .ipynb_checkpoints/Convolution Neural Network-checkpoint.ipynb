{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANt5Z6ALSKzo"
   },
   "source": [
    "# CNN Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhtKpOyKSKzt"
   },
   "source": [
    "## Introduction\n",
    "Hey guys, the Stats Whisper is back with another task at hand. This time we will be using a convulution neural network to resolve a doopleganger debate. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYK8DjBBSKzv"
   },
   "source": [
    "## CNN Explianed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KvhLsW6SKzw"
   },
   "source": [
    "- images\n",
    "- videos \n",
    "- mathematically explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRucqAgBSKzx"
   },
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tmu0Q1k_SKzz"
   },
   "source": [
    "Importing appropriate libraries and image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iIKYLobSKz0",
    "outputId": "8206a6f1-87f8-4f4b-9153-1f745de882e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "#VGG16 is not VGGFACE. VGG16 includes all types of images and not just faces. \n",
    "\n",
    "#keras.applications.imagenet_utils import _obtain_input_shape\n",
    "model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPMuQORuSKz_"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "K.set_image_dim_ordering('th')\n",
    "from time import time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWaNWMgtSK0E",
    "outputId": "1eff896c-37d9-4e32-f012-edb2214f8d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5 \n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(250, 250),  # all images will be resized to 250x250\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(250, 250),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"tensorBoard/\".format(time()), write_images=True, write_graph=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGKYFda6SK0L",
    "outputId": "a4b92095-0673-49d7-e9dd-962129b93932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 13s 643ms/step - loss: 11.4438 - acc: 0.2900 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 13s 637ms/step - loss: 11.2827 - acc: 0.3000 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 13s 640ms/step - loss: 11.2827 - acc: 0.3000 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 13s 639ms/step - loss: 11.4438 - acc: 0.2900 - val_loss: 11.6050 - val_acc: 0.2800\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 13s 638ms/step - loss: 10.9603 - acc: 0.3200 - val_loss: 10.6379 - val_acc: 0.3400\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        callbacks = [tensorboard])\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ral9E7SFSK0S"
   },
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HQYJlJdSK0X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convolution Neural Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
