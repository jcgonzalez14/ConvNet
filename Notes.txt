Notes:

3/31/19
 - importing VGGFace was not working so I had to go to /usr/local/lib/python3.6/dist-packages/keras_vggface/models.py to change to by changing period to underscore:
 - from keras_applications.imagenet_utils import _obtain_input_shape 


Things to work on:
 - Tensorboard
 - CNN visualized 
 - Add Google Analytics tracking code
 - include links/estimated reading time 


Parameters to adjust:
 - batch 
 - epochs
 - optimizer
 - loss
 - model 

Cropping the pictures closer to the users face helps model accuracy rates but have yet to see those high rates for the validation set. 
- Possible reason is the model is not regularized properly or learning rate is too large

Model Loss Explained:
-Loss: is a number indicating how bad the model prediction was. Therefore, high loss means bad prediction versus a low loss means a good prediction

*It seems that by cropping the images closer to the faces, improves the accuracy of the model.

*Initially, the train and validation had 50/50 of the data with 15 faces each class. By doing 24 faces for train and 6 for validation, the training and, more importantly, the validation rates when way up hovering over 90%. 
-downside: accuracy would go up and down suggesting either overfitting or the model is learning too fast.

